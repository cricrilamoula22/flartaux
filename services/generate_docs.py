import os
import zipfile
import pprint
import html
import unicodedata
import xml.etree.ElementTree as ET
import re
from python_odt_template import ODTTemplate
from python_odt_template.jinja import get_odt_renderer
from models import db, TreeCategories
# =========================
# üìÅ Chemins de base
# =========================
TEMPLATE_PATH = "app/templates/template.odt"
OUTPUT_DIR = "app/static/generated_docs"
os.makedirs(OUTPUT_DIR, exist_ok=True)


# =========================
# ‚úÖ Validation XML
# =========================
def is_valid_xml_char(c):
    """
    Retourne True si le caract√®re est autoris√© en XML 1.0.
    Les plages √©tendues sont n√©cessaires pour supporter tous les caract√®res UTF-8.
    """
    codepoint = ord(c)
    # 0x9 (TAB), 0xA (LF), 0xD (CR)
    # Plages r√©guli√®res (0x20 √† 0xD7FF)
    # Plages priv√©es et √©tendues (0xE000 √† 0xFFFD et au-del√† de 0x10000)
    return (
        codepoint == 0x9
        or codepoint == 0xA
        or codepoint == 0xD
        or (0x20 <= codepoint <= 0xD7FF)
        or (0xE000 <= codepoint <= 0xFFFD)
        or (0x10000 <= codepoint <= 0x10FFFF)
    )


# =========================
# üßº Nettoyage des cha√Ænes
# =========================
def clean_and_escape(value):
    """Nettoie et √©chappe une valeur pour garantir une insertion XML UTF-8 s√ªre."""
    if not isinstance(value, str):
        return value

    # --- √âtape 1: √âlimination BRUTALE des caract√®res de contr√¥le non XML valides ---
    # Ceci est essentiel pour corriger l'erreur 'invalid token' et assurer la fusion.
    # Regex pour les caract√®res ASCII 0x00-0x08, 0x0B, 0x0C, 0x0E-0x1F.
    control_chars = re.compile(r'[\x00-\x08\x0B\x0C\x0E-\x1F]')
    value = control_chars.sub('', value)
    
    # --- √âtape 2: Remplacement des accents par des lettres sans accent ---
    
    # Remplacement du caract√®re de remplacement U+FFFD () par "??".
    value = value.replace('\ufffd', '??') 

    # Normalisation Unicode pour d√©composer les caract√®res accentu√©s (ex: '√©' -> 'e' + accent)
    # Puis on retire les marques diacritiques.
    try:
        normalized_value = unicodedata.normalize('NFD', value)
        # Filtre pour ne garder que les caract√®res de base (lettres non accentu√©es, chiffres, ponctuation)
        value = ''.join(c for c in normalized_value if unicodedata.category(c) != 'Mn')
    except Exception as e:
        # En cas d'√©chec, on logue et on continue avec la valeur non trait√©e.
        print(f"Erreur lors de la suppression des accents: {e}")
        
    # --- √âtape 3: Finalisation XML ---

    # Normalisation Unicode (gard√©e par principe)
    value = unicodedata.normalize("NFC", value)

    # Suppression des caract√®res interdits XML (ceux qui sont en dehors des plages autoris√©es)
    value = "".join(c for c in value if is_valid_xml_char(c))

    # √âchappement HTML des caract√®res sp√©ciaux (& < >)
    value = html.escape(value, quote=False)

    # Uniformisation des retours √† la ligne
    value = value.replace("\r\n", "\n").replace("\r", "\n")

    return value


def sanitize_context(context):
    """Applique le nettoyage √† tout le dictionnaire de rendu."""
    def clean_dict(d):
        cleaned = {}
        for k, v in d.items():
            new_v = clean_and_escape(v)
            if isinstance(v, str) and v != new_v:
                # Affichage des corrections si elles ont eu lieu (utile pour le debug)
                # Utiliser repr() permet de voir les caract√®res invisibles comme '\n' ou '\x00'
                print(f"[‚úîÔ∏è Nettoy√©] champ '{k}' : {repr(v)[:50]}... ‚Üí {repr(new_v)[:50]}...")
            cleaned[k] = new_v
        return cleaned

    # Correction: On s'assure que les champs des dates sont aussi nettoy√©s si n√©cessaire
    context["start_date"] = clean_and_escape(context.get("start_date", ""))
    context["end_date"] = clean_and_escape(context.get("end_date", ""))

    context["main_record"] = clean_dict(context["main_record"])
    context["sub_records"] = [clean_dict(sub) for sub in context["sub_records"]]
    return context


# =========================
# üîç Contr√¥le des caract√®res interdits
# =========================
def scan_for_invalid_chars(text, label):
    """Affiche les caract√®res interdits (rare, mais utile en debug)."""
    for i, c in enumerate(text):
        if not is_valid_xml_char(c):
            print(
                f"[‚ùå Caract√®re interdit] {label} ‚Äî pos {i} ‚Äî {repr(c)} ‚Äî code {ord(c)}"
            )


# =========================
# üß© V√©rification du fichier .odt
# =========================
def is_odt_valid(odt_path):
    """Retourne True si le fichier ODT est bien form√©, sinon le message d‚Äôerreur."""
    try:
        with zipfile.ZipFile(odt_path, "r") as odt_zip:
            with odt_zip.open("content.xml") as content_file:
                ET.parse(content_file)
        return True
    except Exception as e:
        return str(e)

def get_name_cat_hfsql(id_sous_priorite=12):
    """R√©cup√®re le lib_sous_priorite depuis HFSQL via ODBC."""
    conn_str = r"Driver=HFSQL ODBC;Server=MONSERVEUR;Database=MA_BASE;Uid=monuser;Pwd=monmdp;"
    try:
        conn = pypyodbc.connect(conn_str)
        cursor = conn.cursor()
        query = "SELECT lib_sous_priorite FROM t_sous_priorite WHERE idt_sous_priorite = ?"
        cursor.execute(query, (id_sous_priorite,))
        row = cursor.fetchone()
        return row[0] if row else None
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur HFSQL : {e}")
        return None
    finally:
        try:
            cursor.close()
            conn.close()
        except:
            pass
# =========================
# üß† Fusion & g√©n√©ration
# =========================
def generate_odt_and_zip(main_records, sub_records, start_date, end_date):
    """
    Fusionne les dossiers principaux et sous-enregistrements,
    g√©n√®re les fichiers ODT et cr√©e un ZIP final.
    """
    generated_files = []
    corrupted_files = []
    renderer = get_odt_renderer(media_path="media/")

    for record in main_records:
        no_interne = record["no_interne"]
        current_sub_records = sub_records.get(no_interne, [])
        print(f"\nüìÑ Fusion du dossier {no_interne} avec {len(current_sub_records)} sous-enregistrements")

        # ‚úÖ Contexte avec s√©paration HFSQL / PostgreSQL
        context = {
            "main_record": record,  # Contient d√©j√† type_name et motif_name
            "sub_records": current_sub_records,
            "start_date": start_date.strftime("%d/%m/%Y"),
            "end_date": end_date.strftime("%d/%m/%Y"),
            "page_break": "\n---PAGEBREAK---\n",
        }

        temp_path = os.path.join(OUTPUT_DIR, f"{no_interne}.odt")
        pprint.pprint(context)

        with ODTTemplate(TEMPLATE_PATH) as template:
            sanitized = sanitize_context(context)

            # V√©rification manuelle (facultative)
            for k, v in sanitized["main_record"].items():
                if isinstance(v, str):
                    scan_for_invalid_chars(v, f"{no_interne}:{k}")
            for sub in sanitized["sub_records"]:
                for k, v in sub.items():
                    if isinstance(v, str):
                        scan_for_invalid_chars(v, f"{no_interne}:{k}")

            rendered = renderer.render(template, sanitized)
            template.pack(temp_path)

        # Validation XML
        validation = is_odt_valid(temp_path)
        if validation is True:
            print(f"‚úÖ Fichier g√©n√©r√© et valide : {temp_path}")
            generated_files.append(temp_path)
        else:
            print(f"‚ùå Fichier corrompu : {temp_path}\n    Erreur : {validation}")
            corrupted_files.append((temp_path, validation))

    # Cr√©ation du ZIP final
    zip_path = os.path.join(OUTPUT_DIR, "documents_fusionnes.zip")
    with zipfile.ZipFile(zip_path, "w") as zipf:
        for f in generated_files:
            zipf.write(f, os.path.basename(f))

    print(f"\n‚úÖ {len(generated_files)} fichiers valides ajout√©s au ZIP.")
    if corrupted_files:
        print(f"‚ö†Ô∏è {len(corrupted_files)} fichiers corrompus d√©tect√©s.")

    return zip_path
